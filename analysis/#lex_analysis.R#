library(ggplot2)
library(reshape)
library(lme4.0)
library(dplyr)

setwd("/Users/km/Dropbox/lexicon/analysis")

dat <- list.files('../rfiles/all_runs')
ind <- dat[grep('^ind', dat)]
dat <- dat[grep('^global', dat)]
d <- NULL
for (i in dat) {
    df <- read.csv(paste('../rfiles/all_runs/', i, sep=''))
    df$f <- i
    d <- rbind(d, df)
            }

d.ind <- NULL
for (i in ind) {
    df <- read.csv(paste('../rfiles/all_runs/', i, sep=''))
    df$f <- i
    df$f <- gsub('_syll_', '', df$f)
    df$f <- gsub('_pcfg_', '', df$f)
    df$f <- gsub('_smoothing0.01', '', df$f)
    df$f <- gsub('manual_', '', df$f)
    df$f <- gsub('\\.txt', '', df$f)
    d.ind <- rbind(d.ind, df)
            }

d$f <- gsub('_syll_', '', d$f)
d$f <- gsub('_pcfg_', '', d$f)
d$f <- gsub('_smoothing0.01', '', d$f)
d$f <- gsub('manual_', '', d$f)
d$f <- gsub('\\.txt', '', d$f)

d <- cbind(d, colsplit(d$f, split='_', names = c('global', 'lex', 'lemma', 'lang', 'mono', 'homo1', 'homo2', 'size', 'cv', 'iter', 'model', 'n')))
d.ind <- cbind(d.ind, colsplit(d.ind$f, split='_', names = c('global', 'lex', 'lemma', 'lang', 'mono', 'homo1', 'homo2', 'size', 'cv', 'iter', 'model', 'n')))

d$model.n <- paste(d$model, d$n, sep='_')
d.ind$model.n <- paste(d.ind$model, d.ind$n, sep='_')
makehist.global <- function(d, v, title)
{
 d$value <- d[ , v]
real <- d[d$lexicon == 'real', ]
 sims <- d[d$lexicon != 'real', ]
 z <- mean(sims$value) - 1.96*sd(sims$value)
  z2 <- mean(sims$value) + 1.96*sd(sims$value)
 p <- ggplot(sims, aes(value, fill=as.factor(model.n)))
p <- p + geom_histogram(position ='identity', alpha=.3) + xlab(v) + theme(legend.position = 'right')
p <- p + geom_point(data=real, aes(value, 0), size = 3, colour = 'red')   + ggtitle(title) + facet_grid(lang ~ .) #+     geom_vline(xintercept =c(z, z2), linetype = 'longdash')
print(p)
}

pdf('global_pdfs.pdf')
for (j in c('mps', 'neighbors', 'avg_lev', 'avg_cluster', 'transitivity', 'bppair', 'tdpair', 'kgpair', 'X1entropy', 'X2entropy' ,'X3entropy', 'X4entropy', 'X5entropy', 'pctunique1', 'pctunique2', 'pctunique3', 'pctunique4', 'pctunique5')) {
makehist.global(d, j, j)}
dev.off()

l = 4 
v = 'neighbors'
d <- d.ind
makehist.ind <- function(d, v, title, l)
{
    d <- filter(d, length==l)
    d <- group_by(d, lexicon, lang, model.n)
    d$v <- d[, v]
    d <- summarise(d, value=mean(v, na.rm=T))
    
real <- d[d$lexicon == 'real', ]
 sims <- d[d$lexicon != 'real', ]
 z <- mean(sims$value) - 1.96*sd(sims$value)
  z2 <- mean(sims$value) + 1.96*sd(sims$value)
 p <- ggplot(sims, aes(value, fill=as.factor(model.n)))
p <- p + geom_histogram(alpha=.3) + xlab(v) + theme(legend.position = 'none')
p <- p + geom_point(data=real, aes(value, 0), size = 3, colour = 'red')   + ggtitle(title)  + facet_grid(lang ~ .) #+ geom_vline(xintercept =c(z, z2), linetype = 'longdash')
print(p)
}

for (x in c('mps', 'neighbors', 'numthatshareletter1', 'numthatshareletter2', 'numthatshareletter3', 'numthatshareletter4', 'numthatshareletter5'))
    {
        pdf(paste('stats_', x, '.pdf', sep=''))
        for (y in seq(2, 7))
            {
                makehist.ind(d.ind, x, paste(x, y, 'letters'), y)
            }
        dev.off()
    }

